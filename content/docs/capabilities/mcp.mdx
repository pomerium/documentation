---
title: 'Model Context Protocol (MCP) Support'
sidebar_label: 'Model Context Protocol (MCP)'
lang: en-US
description: 'Secure access to Model Context Protocol servers through Pomerium, enabling AI agents to safely interact with internal resources via standardized interfaces.'
keywords: [MCP, model context protocol, AI agents, LLM, AI gateway]
---

# Model Context Protocol (MCP) Support

Pomerium provides secure access to [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) servers, enabling AI agents and applications to safely interact with your internal resources through standardized interfaces.

### [Protect an MCP Server](/docs/capabilities/mcp/protect-mcp-server)

Proxy an internal MCP server through Pomerium so external AI clients can access it securely — no auth logic needed on the server side.

### [MCP + Upstream OAuth](/docs/capabilities/mcp/mcp-upstream-oauth)

Connect MCP servers to upstream OAuth2 APIs like GitHub, Google Drive, or Notion. Pomerium manages the full OAuth flow and token lifecycle.

### [Tunnel to ChatGPT During Development](/docs/capabilities/mcp/tunnel-to-chatgpt)

Use `ssh -R 0 pom.run` to expose a local MCP server to ChatGPT for development and testing — one command, no setup.

### [Limit MCP Tool Calling](/docs/capabilities/mcp/limit-mcp-tools)

Use Pomerium Policy Language (PPL) to control which MCP tools each user or group can call, with deny-based block lists and allowlists.

### [Develop an MCP UI App](/docs/capabilities/mcp/develop-mcp-ui-app)

Build interactive ChatGPT Apps with custom widgets and tools, secured by Pomerium.

### [Delegate MCP Access to an LLM](/docs/capabilities/mcp/delegate-mcp-to-llm)

Capture the authenticated user's token and pass it to an LLM, enabling the LLM to call MCP servers on the user's behalf.

### [MCP Full Reference](/docs/capabilities/mcp/reference)

Configuration options, token types, security details, session lifecycle, and observability — the complete reference for Pomerium's MCP support.
